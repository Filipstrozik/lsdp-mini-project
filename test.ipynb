{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e430a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.sql.functions import col\n",
    "import os\n",
    "from pyspark.sql.functions import array_join, col\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def create_spark_session():\n",
    "    spark_master_url = os.getenv(\"SPARK_MASTER_URL\", \"spark://localhost:7077\")\n",
    "    return (\n",
    "        SparkSession.builder.appName(\"ReviewClassification\")\n",
    "        .config(\"spark.master\", \"local[1]\")\n",
    "        .config(\"spark.broadcast.compress\", \"true\")\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"512m\")\n",
    "        .config(\"spark.driver.maxResultSize\", \"2g\")\n",
    "        .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67b6959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/29 19:56:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def load_data_from_csv(spark, file_path):\n",
    "    return spark.read.option(\"multiline\", \"true\").option(\"escape\", \"\\\"\").csv(file_path, header=True, inferSchema=True, sep=\",\")\n",
    "\n",
    "df = load_data_from_csv(create_spark_session(), \"spark/data/vectorized_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e13bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: string, username: string, faculty: string, year: int, opinion_weight: double, date: timestamp, professor: string, rating: string, vote_rate: double, course: string, review: string, post_url: string, language: string, vectors: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427380f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+----+--------------+-------------------+---------------+------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "|                 _id| username|faculty|year|opinion_weight|               date|      professor|rating|vote_rate|              course|              review|            post_url|language|             vectors|\n",
      "+--------------------+---------+-------+----+--------------+-------------------+---------------+------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "|680fc4a256db6a858...|Anonymous|   NULL|NULL|          NULL|2008-02-07 16:05:00|Barbara KoÅ‚wzan|   2,5|      0.0|tutaj Mikrobiolog...|Kurs: tutaj Mikro...|https://polwro.co...|      pl|-0.20756520330905...|\n",
      "+--------------------+---------+-------+----+--------------+-------------------+---------------+------+---------+--------------------+--------------------+--------------------+--------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show language column from the dataframe\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afa62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show only vectors\n",
    "# df.select(\"vectors\").show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "328e74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, split\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "def prepare_features(df: DataFrame) -> DataFrame:\n",
    "    # Convert string of space-separated numbers to vector\n",
    "    def string_to_vector(vec_str):\n",
    "        try:\n",
    "            # Split string by whitespace and convert to float array\n",
    "            vec_list = [float(x) for x in vec_str.split()]\n",
    "            return Vectors.dense(vec_list)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    string_to_vector_udf = udf(string_to_vector, VectorUDT())\n",
    "    \n",
    "    return df.select(\n",
    "        string_to_vector_udf(col(\"vectors\")).alias(\"vectors\"),\n",
    "        col(\"rating\").cast(\"string\")\n",
    "    ).repartition(4)\n",
    "\n",
    "prepared_df = prepare_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3841ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vectors: vector, rating: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc92291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             vectors|rating|\n",
      "+--------------------+------+\n",
      "|[-0.1488369554281...|   2,5|\n",
      "|[0.07919885218143...|   4,5|\n",
      "|[-0.0209472067654...|     5|\n",
      "|[-0.0632937103509...|     3|\n",
      "|[-0.0620504021644...|   3,5|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prepared_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7deee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 19:56:36 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Count: 21767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Count: 5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             vectors|rating|\n",
      "+--------------------+------+\n",
      "|[-0.5281942486763...|     5|\n",
      "|[-0.4362084865570...|     2|\n",
      "|[-0.4344595372676...|   2,5|\n",
      "|[-0.4194297492504...|   4,5|\n",
      "|[-0.4090240895748...|     5|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|             vectors|rating|\n",
      "+--------------------+------+\n",
      "|[-0.4356518983840...|     5|\n",
      "|[-0.4043717980384...|     3|\n",
      "|[-0.3931698203086...|   4,5|\n",
      "|[-0.3765598237514...|     5|\n",
      "|[-0.3444329798221...|   5,5|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def split_data(df, train_ratio=0.8):\n",
    "    train_data, test_data = df.randomSplit([train_ratio, 1 - train_ratio], seed=42)\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = split_data(prepared_df)\n",
    "print('Training Data Count:', train_data.count())\n",
    "print('Test Data Count:', test_data.count())\n",
    "train_data.show(5)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb549c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 19:57:43 WARN DAGScheduler: Broadcasting large task binary with size 1547.8 KiB\n",
      "25/04/29 19:57:45 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "25/04/29 19:57:51 WARN DAGScheduler: Broadcasting large task binary with size 1908.8 KiB\n",
      "25/04/29 19:58:09 WARN DAGScheduler: Broadcasting large task binary with size 1547.8 KiB\n",
      "25/04/29 19:58:11 WARN DAGScheduler: Broadcasting large task binary with size 2.4 MiB\n",
      "25/04/29 19:58:14 WARN DAGScheduler: Broadcasting large task binary with size 3.7 MiB\n",
      "25/04/29 19:58:18 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "25/04/29 19:58:21 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "25/04/29 19:58:26 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "25/04/29 19:58:37 WARN DAGScheduler: Broadcasting large task binary with size 10.5 MiB\n",
      "25/04/29 19:58:42 WARN DAGScheduler: Broadcasting large task binary with size 1218.6 KiB\n",
      "25/04/29 19:58:42 WARN DAGScheduler: Broadcasting large task binary with size 1372.0 KiB\n",
      "25/04/29 19:58:43 WARN DAGScheduler: Broadcasting large task binary with size 1472.4 KiB\n",
      "25/04/29 19:58:44 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n",
      "25/04/29 19:58:45 WARN DAGScheduler: Broadcasting large task binary with size 1005.0 KiB\n",
      "25/04/29 19:58:46 WARN DAGScheduler: Broadcasting large task binary with size 1640.2 KiB\n",
      "25/04/29 19:58:50 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "25/04/29 19:59:00 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/04/29 19:59:05 WARN DAGScheduler: Broadcasting large task binary with size 1437.1 KiB\n",
      "25/04/29 19:59:06 WARN DAGScheduler: Broadcasting large task binary with size 3.5 MiB\n",
      "25/04/29 19:59:08 WARN DAGScheduler: Broadcasting large task binary with size 1005.0 KiB\n",
      "25/04/29 19:59:11 WARN DAGScheduler: Broadcasting large task binary with size 1640.2 KiB\n",
      "25/04/29 19:59:20 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "25/04/29 19:59:25 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/04/29 19:59:29 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "25/04/29 19:59:33 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "25/04/29 19:59:37 WARN DAGScheduler: Broadcasting large task binary with size 6.5 MiB\n",
      "25/04/29 19:59:41 WARN DAGScheduler: Broadcasting large task binary with size 8.7 MiB\n",
      "25/04/29 19:59:45 WARN DAGScheduler: Broadcasting large task binary with size 10.9 MiB\n",
      "25/04/29 19:59:50 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "25/04/29 20:00:01 WARN DAGScheduler: Broadcasting large task binary with size 5.7 MiB\n",
      "25/04/29 20:00:05 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "25/04/29 20:00:09 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "25/04/29 20:00:13 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n",
      "25/04/29 20:00:17 WARN DAGScheduler: Broadcasting large task binary with size 5.3 MiB\n",
      "25/04/29 20:00:19 WARN DAGScheduler: Broadcasting large task binary with size 1327.3 KiB\n",
      "25/04/29 20:00:20 WARN DAGScheduler: Broadcasting large task binary with size 1325.9 KiB\n",
      "25/04/29 20:00:21 WARN DAGScheduler: Broadcasting large task binary with size 1467.4 KiB\n",
      "25/04/29 20:00:23 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/04/29 20:00:23 WARN DAGScheduler: Broadcasting large task binary with size 1514.7 KiB\n",
      "25/04/29 20:00:26 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/04/29 20:00:28 WARN DAGScheduler: Broadcasting large task binary with size 14.6 MiB\n",
      "25/04/29 20:00:30 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "25/04/29 20:00:35 WARN DAGScheduler: Broadcasting large task binary with size 2.7 MiB\n",
      "25/04/29 20:00:37 WARN DAGScheduler: Broadcasting large task binary with size 1575.3 KiB\n",
      "25/04/29 20:00:43 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "25/04/29 20:00:52 WARN DAGScheduler: Broadcasting large task binary with size 1325.9 KiB\n",
      "25/04/29 20:00:54 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/04/29 20:00:57 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/04/29 20:01:01 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "25/04/29 20:01:04 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "25/04/29 20:01:08 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "25/04/29 20:01:12 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "25/04/29 20:01:16 WARN DAGScheduler: Broadcasting large task binary with size 8.6 MiB\n",
      "25/04/29 20:01:19 WARN DAGScheduler: Broadcasting large task binary with size 10.7 MiB\n",
      "25/04/29 20:01:23 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "25/04/29 20:01:27 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/04/29 20:01:31 WARN DAGScheduler: Broadcasting large task binary with size 6.8 MiB\n",
      "25/04/29 20:01:34 WARN DAGScheduler: Broadcasting large task binary with size 8.5 MiB\n",
      "25/04/29 20:01:38 WARN DAGScheduler: Broadcasting large task binary with size 8.8 MiB\n",
      "25/04/29 20:01:42 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/04/29 20:01:45 WARN DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n",
      "25/04/29 20:01:49 WARN DAGScheduler: Broadcasting large task binary with size 6.0 MiB\n",
      "25/04/29 20:01:52 WARN DAGScheduler: Broadcasting large task binary with size 7.7 MiB\n",
      "25/04/29 20:01:56 WARN DAGScheduler: Broadcasting large task binary with size 7.0 MiB\n",
      "25/04/29 20:02:00 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/04/29 20:02:02 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/04/29 20:02:04 WARN DAGScheduler: Broadcasting large task binary with size 1536.7 KiB\n",
      "25/04/29 20:02:05 WARN DAGScheduler: Broadcasting large task binary with size 21.6 MiB\n",
      "25/04/29 20:02:49 WARN DAGScheduler: Broadcasting large task binary with size 1313.4 KiB\n",
      "25/04/29 20:02:51 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "25/04/29 20:02:54 WARN DAGScheduler: Broadcasting large task binary with size 3.1 MiB\n",
      "25/04/29 20:02:58 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "25/04/29 20:03:02 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "25/04/29 20:03:06 WARN DAGScheduler: Broadcasting large task binary with size 5.0 MiB\n",
      "25/04/29 20:03:10 WARN DAGScheduler: Broadcasting large task binary with size 6.3 MiB\n",
      "25/04/29 20:03:13 WARN DAGScheduler: Broadcasting large task binary with size 8.0 MiB\n",
      "25/04/29 20:03:17 WARN DAGScheduler: Broadcasting large task binary with size 9.7 MiB\n",
      "25/04/29 20:03:21 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "25/04/29 20:03:24 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/04/29 20:03:28 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "25/04/29 20:03:32 WARN DAGScheduler: Broadcasting large task binary with size 8.3 MiB\n",
      "25/04/29 20:03:36 WARN DAGScheduler: Broadcasting large task binary with size 8.1 MiB\n",
      "25/04/29 20:03:39 WARN DAGScheduler: Broadcasting large task binary with size 5.5 MiB\n",
      "25/04/29 20:03:43 WARN DAGScheduler: Broadcasting large task binary with size 5.2 MiB\n",
      "25/04/29 20:03:47 WARN DAGScheduler: Broadcasting large task binary with size 6.7 MiB\n",
      "25/04/29 20:03:51 WARN DAGScheduler: Broadcasting large task binary with size 8.4 MiB\n",
      "25/04/29 20:03:54 WARN DAGScheduler: Broadcasting large task binary with size 7.8 MiB\n",
      "25/04/29 20:03:58 WARN DAGScheduler: Broadcasting large task binary with size 7.4 MiB\n",
      "25/04/29 20:04:02 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "25/04/29 20:04:04 WARN DAGScheduler: Broadcasting large task binary with size 4.8 MiB\n",
      "25/04/29 20:04:07 WARN DAGScheduler: Broadcasting large task binary with size 6.1 MiB\n",
      "25/04/29 20:04:10 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n",
      "25/04/29 20:04:13 WARN DAGScheduler: Broadcasting large task binary with size 6.2 MiB\n",
      "25/04/29 20:04:16 WARN DAGScheduler: Broadcasting large task binary with size 3.0 MiB\n",
      "25/04/29 20:04:39 WARN DAGScheduler: Broadcasting large task binary with size 25.7 MiB\n",
      "25/04/29 20:04:47 WARN DAGScheduler: Broadcasting large task binary with size 25.7 MiB\n",
      "25/04/29 20:04:56 WARN DAGScheduler: Broadcasting large task binary with size 25.7 MiB\n",
      "25/04/29 20:05:04 WARN DAGScheduler: Broadcasting large task binary with size 25.7 MiB\n",
      "[Stage 572:==========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.37784580065046874\n",
      "F1 Score: 0.3568867934716005\n",
      "Precision: 0.41438791483458204\n",
      "Recall: 0.3778458006504687\n",
      "\n",
      "Rating to Label Mapping:\n",
      "Rating 5 -> Label 0\n",
      "Rating 5,5 -> Label 1\n",
      "Rating 4,5 -> Label 2\n",
      "Rating 4 -> Label 3\n",
      "Rating 3,5 -> Label 4\n",
      "Rating 3 -> Label 5\n",
      "Rating 2 -> Label 6\n",
      "Rating 2,5 -> Label 7\n",
      "\n",
      "Feature Importances:\n",
      "(768,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767],[0.0043049872457900295,0.0023238728051628832,0.0024577434435163197,0.0018314404993425085,0.0014982415306214899,0.0012331362932708708,0.0011077153210330359,0.0011049191583934858,0.0009502767657441,0.0011500299458775897,0.0010912105483725414,0.0009648011623033644,0.0009675197819381008,0.000901527483262826,0.0009309392231255476,0.000880402892264734,0.0008947297504013653,0.0010840285993660526,0.0009476581277964176,0.0011022784723391168,0.000987125371641943,0.001076992105375513,0.000713321587960375,0.0008731267699706266,0.0009589236253988876,0.000799756750386442,0.0009183579381978917,0.0006159218183008569,0.0011061942353817954,0.0018727086930361329,0.0012705827996154042,0.0010787786138722537,0.0012072888824833415,0.0011282919919376898,0.0014290669490791184,0.0018968872960282294,0.0009710764859827844,0.0012311330520779784,0.0013017189426501007,0.0012543477304893865,0.0014484230897409012,0.001317586174144631,0.001208310633027046,0.0012056834912427604,0.0010910978504891013,0.0029460956638811065,0.0009173815985411153,0.0011748715926758087,0.0014725114838121172,0.0012908042148504159,0.0012410762040931853,0.0012049313424906415,0.001665308109152223,0.0010777203607916916,0.000787983436487224,0.00111322569339241,0.001283200122528642,0.0015580665221634053,0.0023368851220880085,0.0014585744097875258,0.0027559830125684207,0.0009269002137669918,0.0010947601718979524,0.001111054038705512,0.0010833494668153652,0.0012939019126051465,0.001243366702787056,0.0010845698454585628,0.0011009190861365702,0.0011759506588525448,0.0009232176745435353,0.0012039824280811796,0.0013692962089656543,0.0011661215364667402,0.0011027370699551544,0.0013152934218292642,0.0009722452784753498,0.0010209825660187119,0.0016177272555710617,0.0009394767189724176,0.0011746977580308466,0.0013071911527691782,0.0011357208676290643,0.001259906569418814,0.0012157732276473615,0.001091079138800142,0.0011504746942277758,0.0011588021154943884,0.0014718584710888018,0.0010588955649320005,0.001535432745976021,0.0016209909528001228,0.0013538154449067718,0.001129124421393208,0.00193455069768865,0.0012446778579262166,0.001231355316403249,0.0020510167102394954,0.0011767849448213324,0.0014644197208142627,0.001876475354612337,0.0010694918165730467,0.0011994585219214865,0.0012040450328440733,0.001228071388668371,0.0012479968821203125,0.0015591436486395648,0.0014259957652752995,0.0014890406235656777,0.0008553961767416428,0.0011555234228939816,0.0013848935448002762,0.0012153281802580042,0.0012167707272195748,0.00114680457431601,0.0013614304781071301,0.0010591696694409642,0.0010688126273888676,0.0012871052625812451,0.0014442013271600608,0.0009517427087554258,0.00091676404490564,0.0014000689136247832,0.0016975799761459567,0.0009492756370855885,0.0012674568720431303,0.0011541038309049348,0.000949841909720572,0.001991697362611565,0.0010256156744576704,0.0027043361773534174,0.001027324473944071,0.001358218445323479,0.0013699193303857544,0.0011819096855892727,0.0014821010738478393,0.0017789692279447215,0.001187111033657214,0.001271785965239301,0.0017668828356433592,0.0015368672234538495,0.0008263305997113307,0.0011828752125970985,0.0011201150741235299,0.0014579980673453626,0.0011135456628745366,0.0015226791905547494,0.001385636790138029,0.0014219314388543831,0.001259205844879394,0.001118614297529027,0.0013441646090205715,0.00098302478393864,0.0011163012425326716,0.0011967310146729694,0.0011812728144889241,0.0012677639069926165,0.0012843123558834483,0.0010069372766188555,0.0014842003541152208,0.0027402834515641373,0.0012954428855548494,0.0013893556539115678,0.0013751607748238128,0.0011659424251969424,0.001644851919728749,0.0019301199552520258,0.001353346383983616,0.001222060461968059,0.0011444261856719351,0.0012467963284018345,0.0014712548852642373,0.0010852986877302264,0.0010601506119304132,0.001128970328425258,0.0015234560960665454,0.0012532287679857615,0.0012515814405925812,0.0011218938744640239,0.0011815167965956363,0.0012991752717186106,0.001219628669104643,0.0023537461253171337,0.001147922416531413,0.0010214242583886093,0.0009333457281118839,0.0012803569330394487,0.0008980081688137548,0.0010716907305348621,0.0011443515878312557,0.0012280332770946548,0.0009899275789482663,0.001280858061435854,0.0017042510811648222,0.0011988350771644138,0.0011821627700419975,0.0011622353607405457,0.0014667614069721392,0.0013149349534580207,0.001483639901007613,0.000941336252073215,0.0012038595504324664,0.0016123721993319107,0.0010504693550136052,0.0011016318261897933,0.002129841274739163,0.0011390644712458663,0.0011600606318065137,0.0012828705302918336,0.0014041073302431479,0.0016930672587075388,0.0018046504797309155,0.0015232389332333614,0.0010291347001191889,0.0014558592174779795,0.0012621592218290247,0.0010988509117350368,0.0012882803147533529,0.0012457783921619998,0.0010733048416090376,0.0013574011099243613,0.0011625981731868272,0.0011130258716421618,0.0011305000359641754,0.0014159296158272607,0.0011572488645932419,0.001937547193564462,0.001265887484495915,0.0013442831495284711,0.0009953062017097932,0.0011901196068837602,0.0012609260665096397,0.0011311758736969786,0.0011666688572551935,0.0010445850537362802,0.0014022043307118997,0.0011236574332799008,0.0013312443990266738,0.0013260182167697556,0.0012959275855470636,0.0014741808465130542,0.0013677944607923197,0.001108735753503751,0.0013355083127458073,0.0010089356344698001,0.0014515230046926197,0.001354391031430038,0.0008871992213757796,0.0011852510383524321,0.001747848926072152,0.0011574860654292053,0.0015074701666255353,0.0012281594902267287,0.0010633877207471647,0.0014854234056261683,0.0013128245207426747,0.001299672390998284,0.004025473881281941,0.0010597648620423521,0.0010895558316308428,0.0011045884880138245,0.0012012848216895447,0.0013363606609018924,0.0012061196036895383,0.0009799372135472315,0.0010448941462385673,0.0012286257286899258,0.0016574389379700888,0.0013832355383951833,0.0013849330687458708,0.0011183062285108378,0.001019469364867651,0.0011248257822359814,0.0011643542671692258,0.0018353685197679413,0.0014002256636916376,0.0011666801568703657,0.0012188848945223593,0.0011488232868041017,0.0012309177494270373,0.0010850201655502568,0.0010630935181221973,0.0012360431090509558,0.0016262796738290466,0.001173862128536372,0.0014977496132257669,0.0011998740761353704,0.0012132100751169315,0.0010500099894071133,0.0012381650247759465,0.0013004411232111044,0.0010287030930017772,0.0009809434710465572,0.001402006641472781,0.0011748039559172424,0.0010580516289925496,0.0011236624004435972,0.0013113824917897283,0.0014435706242860475,0.0013062012013148026,0.0010030900354860977,0.0010290189351575968,0.001411116012289744,0.0010857167327949133,0.0015468929861830883,0.0010697972740654216,0.001107390310080493,0.0013284183668185925,0.0011952805850166345,0.001178850055271837,0.0012320243091545194,0.0010043065654935773,0.001367806237000616,0.0009767601958467398,0.0011356549933008854,0.0012809573014940436,0.0012055657137022388,0.0009598673798486044,0.0012402906547274183,0.0013247066217140745,0.001059074905189627,0.0014169952007366227,0.001469297001269155,0.0012526495776724604,0.001199960344832621,0.0009361718859064971,0.0012711496245395779,0.0013433168244480894,0.001136093328384267,0.0013280895209476925,0.0011993804468204046,0.0011113023310175781,0.0013114217095165955,0.0015642784331372295,0.001294062882841175,0.0012436746009429872,0.0024091210474310423,0.0009616403508070239,0.0015207444487352637,0.0012426736208537527,0.0011137946968217034,0.0011895357286084939,0.0008538161343057331,0.0011936118064834929,0.001120628422573686,0.001191458097144079,0.0013080783429682248,0.0012250091333284644,0.0017193962044412118,0.0013472638206238501,0.0011259904825618795,0.0010401260167772466,0.0010603678115822352,0.0010296839790228701,0.001317443682544688,0.001060525320947168,0.001389948351005901,0.0010427232469102036,0.0011426904940598245,0.0016241622585629822,0.0010515367618584967,0.0010829861566941192,0.001197499604585591,0.0016882839342347127,0.0012136108375583883,0.0022095932294723787,0.001369237294797273,0.0011451288229794433,0.0012490038199529333,0.001475334462548784,0.001685614867792875,0.001083253617754591,0.0014357627158709668,0.001665200986969275,0.0016033500753041459,0.0016632916636504078,0.001129853919434351,0.0009518620603038075,0.0013497048755314561,0.001076037938387019,0.0011565372696698932,0.0016137813696292214,0.0010590998129112834,0.0016095782784533823,0.0011043087764001705,0.001018410294032808,0.001180505158430204,0.0012196795462082433,0.001089976614770288,0.0012126246374562198,0.0011975852247143644,0.0009159577801179787,0.00121777802625727,0.0012991688730091338,0.0018558951112621917,0.001134001348843514,0.0012849975117706415,0.0011497489398237064,0.0008681045110310795,0.0010965623028314434,0.001212121296105212,0.0011483057686814534,0.0011318749093123428,0.0011741609903348086,0.001592384095228711,0.0010973340405225306,0.0011807792279295052,0.001058754379471363,0.0011174176171723103,0.001233567339323318,0.0012538976199955025,0.000889045681728623,0.0011647259468449361,0.001121618422684169,0.001155121062613474,0.0014094370160718944,0.001146240964186854,0.0012692219068199334,0.0014029604351873935,0.0011854437434887237,0.0014608357929994382,0.001328125768877557,0.0011530996267814322,0.001311298140931425,0.001620475768072614,0.0012230435975879948,0.0012612743662568987,0.0012893327677755727,0.0011056029211312971,0.0011255140748251723,0.001251737707165045,0.0012204883415416407,0.0016422239404041568,0.0011702532635284927,0.0012684713621430126,0.0014385460850549305,0.0011867831514110099,0.001441670193927663,0.0011550416000035077,0.001512808349185341,0.0008693602613584811,0.001597937785753124,0.0012638997283478128,0.001312441599131835,0.001067354255789974,0.001314975365446067,0.0012700271799377378,0.0012626567474134029,0.0011960249185594433,0.0011301026339721179,0.001511491727977713,0.0011934850952672186,0.0012069704340690634,0.0010844925570369025,0.0018177198309808507,0.0012055722363251927,0.0016407297910118973,0.001474330893354935,0.0017136369676848686,0.0011146686322833067,0.0012836229154023263,0.0014279824926862262,0.0010927394224627945,0.0013580483330074946,0.0013821739434039858,0.0013946093485953431,0.001251897117053472,0.0011852599199891894,0.0014363134262234765,0.0012385478331013403,0.0011080143706516795,0.001212309128120806,0.0017428704151640502,0.0013652000327806992,0.0029273126107532904,0.0011710264957083012,0.001349120140404945,0.0009890495578204752,0.0012980976206401409,0.001017319007432301,0.0011165049375864127,0.0012058427029350758,0.0031039259860264562,0.0010938370209463636,0.0012480530545071677,0.0014921087569174755,0.0012940829556060411,0.001696174200334938,0.0011817391513186685,0.0010934403355550794,0.0010835652214999222,0.0011606455347566594,0.0009811432218252737,0.001007745245516045,0.001426438399302969,0.0011947209258440623,0.0014385408237881175,0.0012261547786338242,0.0010724899067989454,0.001152986504507133,0.0011191124203574847,0.001206873395562455,0.0012319876296186128,0.001040128840463173,0.001551816411687165,0.00110674786966998,0.001518574530901267,0.0009106140699332514,0.0012982373291286437,0.0014135449429591087,0.0012094210850897525,0.0010280935890118594,0.001422970778815261,0.0013964760617086937,0.00124184787899901,0.0011940420634676606,0.0012667725763208227,0.0011955295256786556,0.001139846411872053,0.0010371474485079597,0.001517584812612476,0.0013231446889676694,0.0007788694316620098,0.0010000196589861458,0.002676139845719339,0.001231366096100923,0.00129720407777804,0.0012948359689072808,0.003473358828707301,0.0015507561887845456,0.001403743304615337,0.0013968738747587967,0.002233646392667652,0.001291774770863991,0.0013216738905383303,0.0012886375695403977,0.001102537333499301,0.0012194369470733125,0.0012711880059020886,0.0012398466345933613,0.0009180442527651588,0.001336279412795692,0.0009724247432588804,0.001437217353778229,0.000962719907799862,0.0014561282522744044,0.001193368347520035,0.0013537894487166873,0.0027717635427853813,0.0012359683197300957,0.0012948948577409926,0.0011551036902610863,0.0014163688007521593,0.001581973195964482,0.0016788467013043094,0.0012230231148952606,0.0012827778148844383,0.0012447390641603254,0.0011794696769776806,0.0016481982078598815,0.0008804836107829731,0.0012645792017687465,0.0010638064549898395,0.0011303892254773326,0.0013733830111013717,0.0020385974521342663,0.0012528503810470294,0.0016112969719234268,0.0011279699398084727,0.0012004059067268907,0.0009854726036898475,0.0012413401440653207,0.0014553031724911676,0.0015145264055692687,0.0010707127285748317,0.0011313967118318031,0.0011654629941310652,0.0010702081530477071,0.001193125965576934,0.0012689253515108772,0.0012688320996705356,0.002707987475450416,0.001188677433466343,0.001997821573228992,0.0011674404561136506,0.0012288925208945366,0.0013471751222970624,0.001113368063043861,0.0012330280788559796,0.00114961781820711,0.001029199834987026,0.00114352959214923,0.0012528724484709016,0.0010819942931853956,0.0011429360392690418,0.0016290783031746307,0.0008874251734730102,0.001090068299386431,0.001123079973866097,0.0011728360350385934,0.0011051566165737748,0.0026171320718960797,0.0012809977022020878,0.0011034038374253827,0.0013754808111149958,0.0010829473418100077,0.0015330115487377284,0.0010341781314785496,0.0013086815983011787,0.0011734546421300685,0.001223790794236828,0.000965704319898747,0.001155182531831185,0.0020445381223383346,0.0014690954094279652,0.0014858765344455567,0.0011174495466612028,0.0014218460184787355,0.0014000475359992304,0.0010079671343425389,0.001331526652347537,0.0011456578609348874,0.0012449031263172198,0.0016334198296764108,0.001035588654458145,0.0012546483602758282,0.0009421082671062283,0.0010244752294420636,0.0010024975988837726,0.0013634393540283545,0.0010450346433188106,0.0015303023606392852,0.0010584414040399619,0.0010753630010318814,0.0016616413337632687,0.001607483431784876,0.0010446973449194435,0.0014067392837351063,0.0011057444189834658,0.001556508468169127,0.0012031030900066786,0.0011304431337810252,0.0013398203075270898,0.0011623168920988827,0.0014465909398692512,0.0011421317416938674,0.001133733575767533,0.0011918223185084786,0.0024040635695235105,0.0010411166802400142,0.0013869068222199764,0.0015393268598275416,0.0020764718381962653,0.0012120454110602374,0.0012372610146931873,0.0010875421286754797,0.0010864373439716042,0.0012841340766948457,0.001205787444942263,0.0013827517023581714,0.0008850799420461894,0.001063697068287752,0.001468450466940211,0.0016195379749290074,0.0013558696569913387,0.0013713826496953975,0.0011158578686248086,0.0012278786641359706,0.00105608026205959,0.0012771323726868322,0.0014249773386970364,0.0013809529696220462,0.0013224923508341332,0.0009555057015679995,0.0010341584675379642,0.0018539029003780487,0.0011633305262502363,0.001044694094499189,0.0013364058543387863,0.0011593419667884368,0.0011366009634956496,0.0013919493749383807,0.0014680890987193375,0.001415425736471343,0.0008711377981051655,0.001298307808151077,0.001375070581621144,0.0012277696320142904,0.0012588416689556746,0.0011447394772943925,0.0010926242963913287,0.0015608387047683129,0.0013232507466499701,0.0016876382743347478,0.0012151693369020981,0.0015761082091718666,0.0012429756963205287,0.0011111530252283185,0.0013997820280021785,0.001225809947593261,0.0014103837363319343,0.0012385179776698311,0.0015049619971185797,0.0011435528190359655,0.0015309241171301553,0.0011946863046111214,0.001262085861997488,0.0015989270474497347,0.0017115392134836687,0.0009279096058720828,0.0012278607939019035,0.0011624955813368501,0.0013411994830031166,0.0013111183678233243,0.0016886178314822573,0.001193469792506733,0.0010508345751512845,0.0013761635193613403,0.001347038743498433,0.002244324107306356,0.001305158068557506,0.0009847797528497288,0.0012205669298024572,0.0011589591000159896,0.0012390743242950732,0.0014774101151483422,0.002499259160348645,0.002746006895959043,0.0012250944664879393,0.0012618401823399023,0.0011710162176966925,0.001072094513307898,0.001090000697239249,0.001219202821876602,0.0013033110924809766,0.0011129151024449721,0.0013576672055933077,0.0013072962712881969,0.0018212310158522498,0.001216289149858621,0.001789107940875385,0.001025102645740385,0.0012289137319342542,0.0011148198458832378,0.0017443588134936304,0.0013103705503610355,0.0015094393400532382,0.0016211518201646087,0.0017225702656035668,0.0012218752461372305,0.0011822447246046138,0.0011274631355780071,0.0013862494939341251,0.0013694553166548426,0.0011868437133120584,0.0011187712281861462,0.001265886784820811,0.001545190524305606,0.0013020344487679849,0.0012481263794260483,0.0011982449060664872,0.001254842511829324,0.0013450276533607712,0.0015487935306436162,0.0010096519813102948,0.0013037613061855713,0.0011911661591617914,0.001296142937129866])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def create_pipeline():\n",
    "    string_indexer = StringIndexer(inputCol=\"rating\", outputCol=\"label\")\n",
    "    assembler = VectorAssembler(inputCols=[\"vectors\"], outputCol=\"features\")\n",
    "\n",
    "    rf = RandomForestClassifier(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        numTrees=10,\n",
    "        maxDepth=5,\n",
    "        seed=42,\n",
    "        cacheNodeIds=False,\n",
    "        maxBins=32,\n",
    "    )\n",
    "\n",
    "    return Pipeline(stages=[string_indexer, assembler, rf])\n",
    "\n",
    "def train_model(pipeline, train_data):\n",
    "    paramGrid = (\n",
    "        ParamGridBuilder()\n",
    "        .addGrid(pipeline.getStages()[-1].numTrees, [10, 20, 30])\n",
    "        .addGrid(pipeline.getStages()[-1].maxDepth, [5, 10, 15])\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    tvs = TrainValidationSplit(\n",
    "        estimator=pipeline,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator,\n",
    "        trainRatio=0.8,\n",
    "        parallelism=2,\n",
    "    )\n",
    "\n",
    "    model = tvs.fit(train_data)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model: TrainValidationSplit, test_data):\n",
    "    predictions = model.bestModel.transform(test_data)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\")\n",
    "\n",
    "    accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "    f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "    precision = evaluator.evaluate(\n",
    "        predictions, {evaluator.metricName: \"weightedPrecision\"}\n",
    "    )\n",
    "    recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "    # Print classification mapping\n",
    "    label_mapping = model.bestModel.stages[0].labels\n",
    "    print(\"\\nRating to Label Mapping:\")\n",
    "    for idx, rating in enumerate(label_mapping):\n",
    "        print(f\"Rating {rating} -> Label {idx}\")\n",
    "\n",
    "    # Print feature importances\n",
    "    rf_model = model.bestModel.stages[-1]\n",
    "    feature_importances = rf_model.featureImportances\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importances)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "pipeline = create_pipeline()\n",
    "model = train_model(pipeline, train_data)\n",
    "\n",
    "predictions = evaluate_model(model, test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862afe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 20:05:07 WARN TaskSetManager: Stage 584 contains a task of very large size (22978 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "model.bestModel.write().overwrite().save(\"spark/models/review_classification_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b87d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MODEL_PATH = \"/app/models/professor_raing_classifier\"\n",
    "# temp_dir = \"/opt/bitnami/spark/work/models/professor_raing_classifier\"\n",
    "# model.bestModel.write().overwrite().save(temp_dir)\n",
    "# os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "# shutil.move(temp_dir, MODEL_PATH)\n",
    "\n",
    "# print(f\"Model saved to {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
